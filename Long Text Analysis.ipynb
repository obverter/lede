{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc, Token, Span\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1, 2: 3, 3: 3, 4: 3, 5: 3, 6: 2, 7: 1, 8: 1, 9: 1, 10: 1, 32: 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2,3,4,5,6,4,3,2,5,32]\n",
    "counter(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yesterday I went fishing. I don't fish that often, \\nso I didn't catch any fish. I was told I'd enjoy myself, \\nbut it didn't really seem that fun.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Yesterday I went fishing. I don't fish that often, \n",
    "so I didn't catch any fish. I was told I'd enjoy myself, \n",
    "but it didn't really seem that fun.\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'i', 'went', 'fishing', 'i', \"don't\", 'fish', 'that', 'often,', '', 'so', 'i', \"didn't\", 'catch', 'any', 'fish', 'i', 'was', 'told', \"i'd\", 'enjoy', 'myself,', '', 'but', 'it', \"didn't\", 'really', 'seem', 'that', 'fun']\n"
     ]
    }
   ],
   "source": [
    "cleaned = text.lower()\n",
    "cleaned = cleaned.replace(\".\",\"\")\n",
    "cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "words = cleaned.split(\" \")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yesterday I went fishing. I don't fish that often, \\nso I didn't catch any fish. I was told I'd enjoy myself, \\nbut it didn't really seem that fun.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = re.sub(\"r[^\\w ]\",\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'i', 'went', 'fishing', 'i', 'dont', 'fish', 'that', 'often', 'so', 'i', 'didnt', 'catch', 'any', 'fish', 'i', 'was', 'told', 'id', 'enjoy', 'myself', 'but', 'it', 'didnt', 'really', 'seem', 'that', 'fun']\n"
     ]
    }
   ],
   "source": [
    "# Normalize everything to lowercase\n",
    "cleaned = text.lower()\n",
    "\n",
    "# We want to get rid of all punctuation\n",
    "# [',', '.', '\"']....\n",
    "cleaned = re.sub(r\"[^\\w ]\", \"\", cleaned)\n",
    "\n",
    "\n",
    "words = cleaned.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "text[4000:4200]\n",
    "doca = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize everything to lowercase\n",
    "cleaned = text.lower()\n",
    "\n",
    "# We want to get rid of all punctuation\n",
    "# [',', '.', '\"']....\n",
    "cleaned = re.sub(r\"[^\\w ]\", \"\", cleaned)\n",
    "\n",
    "\n",
    "words = cleaned.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted = counter(words)\n",
    "counted.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(r\"[Hh]e (\\w+)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 196),\n",
       " ('had', 191),\n",
       " ('could', 112),\n",
       " ('is', 61),\n",
       " ('would', 52),\n",
       " ('did', 36),\n",
       " ('saw', 29),\n",
       " ('felt', 27),\n",
       " ('will', 22),\n",
       " ('might', 22)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter(matches).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count all the he ____\n",
    "he_words = re.findall(r\"\\b[Hh]e (\\w+)\", text)\n",
    "# Count all the she ____\n",
    "she_words = re.findall(r\"\\b[Ss]he (\\w+)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>he</th>\n",
       "      <th>she</th>\n",
       "      <th>total</th>\n",
       "      <th>pct_she</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meant</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>came</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>must</th>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replied</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should</th>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>does</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walked</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>41.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>73.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>45.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asked</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>might</th>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continued</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>158.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>54.727794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looked</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>then</th>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoke</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>148.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>56.976744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>57.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>58.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knew</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>29.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>64.197531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thought</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>found</th>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>68.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soon</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>began</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added</th>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>35.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wished</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>84.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>90.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cried</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              he    she  total    pct_she\n",
       "meant       10.0    1.0   11.0   9.090909\n",
       "never       12.0    2.0   14.0  14.285714\n",
       "may         11.0    4.0   15.0  26.666667\n",
       "came        13.0    5.0   18.0  27.777778\n",
       "has         47.0   21.0   68.0  30.882353\n",
       "must        23.0   12.0   35.0  34.285714\n",
       "replied     13.0    8.0   21.0  38.095238\n",
       "should      22.0   14.0   36.0  38.888889\n",
       "does        11.0    7.0   18.0  38.888889\n",
       "walked       7.0    5.0   12.0  41.666667\n",
       "is          73.0   61.0  134.0  45.522388\n",
       "will        23.0   22.0   45.0  48.888889\n",
       "asked        6.0    6.0   12.0  50.000000\n",
       "might       21.0   22.0   43.0  51.162791\n",
       "continued    9.0   10.0   19.0  52.631579\n",
       "and          5.0    6.0   11.0  54.545455\n",
       "made         5.0    6.0   11.0  54.545455\n",
       "had        158.0  191.0  349.0  54.727794\n",
       "looked       8.0   10.0   18.0  55.555556\n",
       "then        11.0   14.0   25.0  56.000000\n",
       "spoke        7.0    9.0   16.0  56.250000\n",
       "was        148.0  196.0  344.0  56.976744\n",
       "did         27.0   36.0   63.0  57.142857\n",
       "said        13.0   18.0   31.0  58.064516\n",
       "knew         4.0    7.0   11.0  63.636364\n",
       "would       29.0   52.0   81.0  64.197531\n",
       "thought      9.0   18.0   27.0  66.666667\n",
       "found        6.0   13.0   19.0  68.421053\n",
       "soon         5.0   11.0   16.0  68.750000\n",
       "began        4.0    9.0   13.0  69.230769\n",
       "went         4.0   10.0   14.0  71.428571\n",
       "added        7.0   21.0   28.0  75.000000\n",
       "could       35.0  112.0  147.0  76.190476\n",
       "wished       2.0   11.0   13.0  84.615385\n",
       "felt         3.0   27.0   30.0  90.000000\n",
       "saw          3.0   29.0   32.0  90.625000\n",
       "cried        1.0   11.0   12.0  91.666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'he': Counter(he_words),\n",
    "    'she': Counter(she_words)    \n",
    "}).fillna(0)\n",
    "\n",
    "df['total'] = df.he + df.she\n",
    "df['pct_she'] = df.she / df.total * 100\n",
    "\n",
    "df[df.total > 10].sort_values(by='pct_she', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello President Biden how are you today?"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello President Biden how are you today?\"\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "President\n",
      "Biden\n",
      "how\n",
      "are\n",
      "you\n",
      "today\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bean/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term '91' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Biden\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " how are you \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension(\"is_color\", default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello President Biden how are you today?"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[chunk.text for chunk in doc.noun_chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello President Biden how are you today?']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/bean/.pyenv/versions/3.10.5/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/Users/bean/.pyenv/versions/3.10.5/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"spacy/tokens/token.pyx\", line 158, in spacy.tokens.token.Token.__reduce__\n",
      "NotImplementedError: [E111] Pickling a token is not supported, because tokens are only views of the parent Doc and can't exist on their own. A pickled token would always have to include its Doc and Vocab, which has practically no advantage over pickling the parent Doc directly. So instead of pickling the token, pickle the Doc it belongs to.\n",
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Process Process-2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bean/Dropbox/code/05_lede/Long Text Analysis.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bean/Dropbox/code/05_lede/Long%20Text%20Analysis.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipe(doc, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, n_process\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, disable\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mner\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bean/Dropbox/code/05_lede/Long%20Text%20Analysis.ipynb#ch0000024?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m([tok\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m doc])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/language.py:1583\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[1;32m   1582\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[1;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/language.py:1657\u001b[0m, in \u001b[0;36mLanguage._multiprocessing_pipe\u001b[0;34m(self, texts, pipes, n_process, batch_size)\u001b[0m\n\u001b[1;32m   1653\u001b[0m byte_tuples \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m   1654\u001b[0m     recv\u001b[39m.\u001b[39mrecv() \u001b[39mfor\u001b[39;00m recv \u001b[39min\u001b[39;00m cycle(bytedocs_recv_ch)\n\u001b[1;32m   1655\u001b[0m )\n\u001b[1;32m   1656\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     \u001b[39mfor\u001b[39;00m i, (_, (byte_doc, context, byte_error)) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m   1658\u001b[0m         \u001b[39mzip\u001b[39m(raw_texts, byte_tuples), \u001b[39m1\u001b[39m\n\u001b[1;32m   1659\u001b[0m     ):\n\u001b[1;32m   1660\u001b[0m         \u001b[39mif\u001b[39;00m byte_doc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1661\u001b[0m             doc \u001b[39m=\u001b[39m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(byte_doc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/language.py:1654\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1649\u001b[0m     proc\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1651\u001b[0m \u001b[39m# Cycle channels not to break the order of docs.\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m \u001b[39m# The received object is a batch of byte-encoded docs, so flatten them with chain.from_iterable.\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m byte_tuples \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 1654\u001b[0m     recv\u001b[39m.\u001b[39;49mrecv() \u001b[39mfor\u001b[39;00m recv \u001b[39min\u001b[39;00m cycle(bytedocs_recv_ch)\n\u001b[1;32m   1655\u001b[0m )\n\u001b[1;32m   1656\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1657\u001b[0m     \u001b[39mfor\u001b[39;00m i, (_, (byte_doc, context, byte_error)) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m   1658\u001b[0m         \u001b[39mzip\u001b[39m(raw_texts, byte_tuples), \u001b[39m1\u001b[39m\n\u001b[1;32m   1659\u001b[0m     ):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/multiprocessing/connection.py:255\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 255\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    256\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    420\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    385\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for doc in nlp.pipe(doc, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
    "    print([tok.lemma_ for tok in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_web_core_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/bean/Dropbox/code/05_lede/Long Text Analysis.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bean/Dropbox/code/05_lede/Long%20Text%20Analysis.ipynb#ch0000025?line=0'>1</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_web_core_md\u001b[39;49m\u001b[39m'\u001b[39;49m, disable\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mner\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mparser\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bean/Dropbox/code/05_lede/Long%20Text%20Analysis.ipynb#ch0000025?line=1'>2</a>\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(nlp\u001b[39m.\u001b[39mcreate_pipe(\u001b[39m'\u001b[39m\u001b[39msentencizer\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     55\u001b[0m         name,\n\u001b[1;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/util.py:436\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_web_core_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_web_core_md', disable=['ner', 'parser'])\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.attrs import *\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "texts = [\"this is some sentence\",\"This is the last sentence\"]\n",
    "max_length =10\n",
    "\n",
    "data = np.zeros((len(texts), max_length), dtype=np.uint64)\n",
    "\n",
    "for row, doc in enumerate(nlp.pipe(texts, batch_size=10000)):\n",
    "    dat = doc.to_array([LEMMA, IS_STOP])\n",
    "    # Check to see if text length is not 0\n",
    "    if len(dat) > 0:\n",
    "        delete = np.where(dat[:, 1] == 1)\n",
    "        dat = np.delete(dat, delete, 0)\n",
    "        length = min(len(dat), max_length)\n",
    "        data[row, :length] = dat[:length, 0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/bean/Dropbox/code/05_lede/Long Text Analysis.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bean/Dropbox/code/05_lede/Long%20Text%20Analysis.ipynb#ch0000029?line=0'>1</a>\u001b[0m nlp(dat)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/language.py:1008\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    988\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    989\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    992\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    993\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[1;32m    994\u001b[0m     \u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1008\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[1;32m   1009\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/spacy/language.py:1102\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[0;32m-> 1102\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "nlp(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/bean/Dropbox/code/05_lede/Long Text Analysis.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bean/Dropbox/code/05_lede/Long%20Text%20Analysis.ipynb#ch0000027?line=0'>1</a>\u001b[0m dat[\u001b[39m\"\u001b[39;49m\u001b[39mBiden\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "dat[Biden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.18 s, sys: 730 ms, total: 5.91 s\n",
      "Wall time: 5.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma = lemmatizer(doca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r\"[^\\w ]\", \"\", lemma).replace(\"  \",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is the last sentence"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# word that comes after a pronoun\n",
    "# with maybe auxiliary verbs in between\n",
    "pattern = [\n",
    "    { \"POS\": \"PRON\" },\n",
    "    { \"POS\": \"AUX\", \"OP\": \"*\" },\n",
    "    { \"POS\": \"VERB\" }\n",
    "]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"HE_SAID\", [pattern])\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "he_words = []\n",
    "she_words = []\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    if span[0].lemma_ == 'he':\n",
    "        he_words.append(span[-1].lemma_)\n",
    "    if span[0].lemma_ == 'she':\n",
    "        she_words.append(span[-1].lemma_)\n",
    "\n",
    "# print(\"----\")\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Russia's Shortfalls Create an\n",
    "Opportunity for Ukraine, Western Officials Say\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russia GPE\n",
      "Shortfalls Create ORG\n",
      "Ukraine GPE\n",
      "Western NORP\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6b95da866a03443eb5722b0ff81448a6-0\" class=\"displacy\" width=\"225\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Russia</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6b95da866a03443eb5722b0ff81448a6-1\" class=\"displacy\" width=\"400\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Shortfalls</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Create</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6b95da866a03443eb5722b0ff81448a6-1-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6b95da866a03443eb5722b0ff81448a6-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6b95da866a03443eb5722b0ff81448a6-2\" class=\"displacy\" width=\"225\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ukraine</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6b95da866a03443eb5722b0ff81448a6-3\" class=\"displacy\" width=\"225\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Western</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON — In the early phase of the war in Ukraine, shortages of soldiers and problems with equipment forced Russia to narrow its mission, abandon its assault on Kyiv and focus its offensive on the east.Now, as the fighting enters its sixth month, critical manpower and equipment problems could ag'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# url = \"https://www.whitehouse.gov/briefing-room/speeches-remarks/2022/03/01/remarks-of-president-joe-biden-state-of-the-union-address-as-delivered/\"\n",
    "url = \"https://www.nytimes.com/2022/08/04/us/politics/russia-weapons-ukraine.html\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "doc = BeautifulSoup(response.text)\n",
    "\n",
    "# doc.select_one(\"[name='articleBody']\")\n",
    "text = doc.find('section', { 'name': 'articleBody' }).text\n",
    "text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "chrome_path = '/Applications/Google Chrome.app%s'\n",
    "webbrowser.get(chrome_path).open(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = displacy.render(doc, style='ent', jupyter=False)\n",
    "clean = BeautifulSoup(html, 'html.parser').get_text()\n",
    "\n",
    "with open(\"fun.html\", 'w+', encoding=\"utf-8\") as fp:\n",
    "    fp.write(html)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/bean/Dropbox/code/05_lede/fun.html'\n",
    "path = webbrowser.open_new_tab(\"file://\" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON — In the early phase of the war in Ukraine, shortages of soldiers and problems with equipment forced Russia to narrow its mission, abandon its assault on Kyiv and focus its offensive on the east.Now, as the fighting enters its sixth month, critical manpower and equipment problems could ag'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# url = \"https://www.whitehouse.gov/briefing-room/speeches-remarks/2022/03/01/remarks-of-president-joe-biden-state-of-the-union-address-as-delivered/\"\n",
    "url = \"https://www.nytimes.com/2022/08/04/us/politics/russia-weapons-ukraine.html\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "doc = BeautifulSoup(response.text)\n",
    "\n",
    "# doc.select_one(\"[name='articleBody']\")\n",
    "text = doc.find('section', { 'name': 'articleBody' }).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_in_browser(doc):\n",
    "    doc = nlp(text)\n",
    "    displacy.render(doc, style='ent', jupyter=False)\n",
    "    clean = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    \n",
    "    with open(\"fun.html\", 'w+', encoding=\"utf-8\") as fp:\n",
    "        fp.write(html)\n",
    "        fp.close()\n",
    "        abs_path = os.path.abspath('fun.html')\n",
    "        path = webbrowser.open_new_tab(\"file://\" + abs_path)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_in_browser(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_path = os.path.abspath('fun.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_in_browser(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open_new_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('3.10.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "134736d2bd8d30a43a7e81209d4f3bae1a364c8aa0c0cc845bdcd189c4629406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
